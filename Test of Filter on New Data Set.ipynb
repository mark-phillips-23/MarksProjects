{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['AGN', 'CV', 'ILRT', 'LBV', 'LRN', 'Nova', 'QSO', 'SLSN-I',\n",
      "       'SLSN-II', 'SN', 'SN II', 'SN II-pec', 'SN IIb', 'SN IIn', 'SN Ia',\n",
      "       'SN Ia-91T', 'SN Ia-91bg-like', 'SN Ia-CSM', 'SN Ia-SC',\n",
      "       'SN Ia-pec', 'SN Iax', 'SN Ib', 'SN Ib-pec', 'SN Ib/c', 'SN Ibn',\n",
      "       'SN Ic', 'SN Ic-BL', 'SN Ic-Ca-rich', 'SN Ic-pec', 'SN Icn', 'TDE',\n",
      "       'Varstar'], dtype='<U17'), array([  47,  103,    1,    7,    1,   14,    4,   89,   49,   11,  957,\n",
      "          4,   58,  196, 4173,  157,   24,   15,    3,   32,   12,   82,\n",
      "          3,   14,   18,   92,   49,    1,    1,    2,   51,    8],\n",
      "      dtype=int64))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "array() got an unexpected keyword argument 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=71'>72</a>\u001b[0m loaded_gm\u001b[39m.\u001b[39mweights_ \u001b[39m=\u001b[39m weights\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=72'>73</a>\u001b[0m loaded_gm\u001b[39m.\u001b[39mprecisions_cholesky_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mcholesky(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(covar))\n\u001b[1;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=73'>74</a>\u001b[0m all_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(all_features, ndim \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m)       \n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=74'>75</a>\u001b[0m \u001b[39m# Isolation Forest\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=75'>76</a>\u001b[0m loaded_IF \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m/Users/pmark/OneDrive/Desktop/Research Materials/Training set/Phillips_IsolationForest.npy\u001b[39m\u001b[39m'\u001b[39m, allow_pickle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: array() got an unexpected keyword argument 'ndim'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster\n",
    "import math as m\n",
    "import seaborn as sns\n",
    "import sklearn.neighbors\n",
    "import sklearn.mixture\n",
    "from scipy import stats\n",
    "from astropy.cosmology import Planck13 as cosmo\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "# Importing the new ZTF dataset as well as their classifications in the training set .csv file\n",
    "\"\"\"\n",
    "all_files = glob.glob(\"/Users/pmark/OneDrive/Desktop/Research Materials/Training set/dynesty_fits/*.npz\")\n",
    "\n",
    "# Reading in and making arrays from training_set_dynesty.csv \n",
    "df_1 = pd.read_csv(\"/Users/pmark/OneDrive/Desktop/SNII Clustering Project Resources/training_set_dynesty.csv\")\n",
    "sn_names = df_1['NAME'].to_numpy()\n",
    "sn_label = df_1['LABEL'].to_numpy()\n",
    "sn_redshift = df_1['Z'].to_numpy()\n",
    "\n",
    "# Forming data arrays and sorting the CSV File and Names\n",
    "sn_ia = [] #Everything with SN-Ia classification in the first part of the name\n",
    "sn_ii = [] #SN-IIp and SN-IIl objects\n",
    "slsn = [] #SLSN-I and SLSN-II's\n",
    "sn_ibc = []  #SN-Ic, SN-Ib, and SN-Ic-BL objects\n",
    "other =[] # QSO, AGN, TDE, CVs, & Other (LBV's, novae, galaxies, variable stars)\n",
    "sn_iin = []\n",
    "sn_iib = []\n",
    "\n",
    "\"\"\"\n",
    "# I am adding some conversions here for events which are either \"candidates\" or have <5 objects\n",
    "conversions = {'SN Ia-91T-like':'SN Ia-91T', 'SN IIn-pec':'SN IIn', 'TDE-H-He':'TDE', 'SN IIP':'SN II', \n",
    "               'SN IIL': 'SN II', 'SN Iax[02cx-like]': 'SN Iax'}\n",
    "def make_dataset(load=False):\n",
    "    # to do - eventually, I do want to save/load a dataset...\n",
    "    if not load:\n",
    "        metadata, all_labels = np.loadtxt('/Users/pmark/OneDrive/Desktop/Research Materials/Training set/training_set_dynesty.csv',usecols=(0,1), \n",
    "                                          delimiter=',', skiprows=1, dtype=str, unpack=True)\n",
    "\n",
    "        gind = np.where((all_labels !='Galaxy') & (all_labels !='Other') &  (all_labels !='M dwarf') & (all_labels !='SN I'))\n",
    "        metadata = metadata[gind]\n",
    "        all_labels = all_labels[gind]\n",
    "        all_dat = np.zeros((len(all_labels),15))\n",
    "        \n",
    "        for key in conversions:\n",
    "            gind = np.where(all_labels == key)\n",
    "            all_labels[gind] = conversions[key]\n",
    "        print(np.unique(all_labels, return_counts=True))\n",
    "\n",
    "        for i, md in enumerate(metadata):\n",
    "            one_sn_data = np.load('/Users/pmark/OneDrive/Desktop/Research Materials/Training set/dynesty_fits/'+md+'_eqwt_dynesty.npz')\n",
    "            all_dat[i] = np.mean(one_sn_data['arr_0'],axis=0)\n",
    "        return(all_labels,all_dat)\n",
    "\n",
    "labels,all_features = make_dataset()\n",
    "anom_scores_GMM = []\n",
    "anom_scores_IF = []\n",
    "\n",
    "# Loading in pre-existing GMM and IF files\n",
    "\n",
    "# GMM\n",
    "means = np.load(\"/Users/pmark/OneDrive/Desktop/Research Materials/Training set/Phillips_deSoto_gm_fit_means.npy\")\n",
    "weights = np.load('/Users/pmark/OneDrive/Desktop/Research Materials/Training set/Phillips_deSoto_gm_fit_weights.npy')\n",
    "covar = np.load('/Users/pmark/OneDrive/Desktop/Research Materials/Training set/Phillips_deSoto_gm_fit_covariances.npy')\n",
    "        \n",
    "loaded_gm = sklearn.mixture.GaussianMixture(n_components = len(means), random_state = 0, covariance_type = 'full')\n",
    "loaded_gm.means_ = means\n",
    "loaded_gm.covariances_ = covar\n",
    "loaded_gm.weights_ = weights\n",
    "loaded_gm.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(covar))\n",
    "all_features = np.array(all_features, ndim = 2)\n",
    "\n",
    "# Isolation Forest\n",
    "loaded_IF = np.load('/Users/pmark/OneDrive/Desktop/Research Materials/Training set/Phillips_IsolationForest.npy', allow_pickle = True)\n",
    "for i in range(len(all_features)):\n",
    "    anom_scores_GMM_i = -1 * loaded_gm.score_samples(all_features[i])\n",
    "    anom_scores_IF_ =  -1 * loaded_IF.score_samples(all_features[i])\n",
    "    np.append(anom_scores_GMM_i, anom_scores_GMM)\n",
    "    np.append(anome_score_IF_i, anom_scores_IF)\n",
    "print(anom_scores_GMM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
